Module 1 - What is an architecture for IntSol?
- Identify Stakeholders () + Communication
- Documenting Strategy (UML?) + a "good" tool (fits the company) --- Collaboration -> API Portals / Draw.io + Wiki/Confluence
- Overall Design / Patterns? (3-4-5) -> Integration Patterns Book -> Integration Terminology
- How to gather FR/NFR - Use Cases / User Stories (the basis for "planning" the roadmap)
- Testing (at all levels) IMPORTANT!!!
- Security (Data, "Phys" (netw/os), Application Ã -la OWASP)
- Design for Performance?

Module 2 - Anypoint Platform
- Collaborative Platform (gather all stakeholders)
- Exchange: Assets (APIs, fragments, templates, policies, connector, examples)
- API Portal + Mocking
- Design Center (Visual Designer) (Data Diagram) Order ----> Resources (/order GET, POST, PUT, PATCH,DELETE)
   - PDU (Protocol Data Unit) "deleteResponse" (status + data order I deleted)
- Runtime Manager (ops) - deployment + mgmgt + monitoring (CloudHub + Customer-Hoster Runtimes)

Module 3 - AP Platform Main Components
1- Api-LED connectivity. 
  - Download from Design Center (implementing the spec) - ApiKit Scaffolding (console, 1 point of entry for error mgmt)
  - Create an API Design project and synch with GIT
  - Use the API spec as a dependency (from Exchange) - versioned asset (1.0.0) (comes from Maven)
  - Connector (loaded as a Module (dependency - pom.xml)).
  - Configuration/Global Elements - Domains (share configuration, app footprint is reduced)
     - connectors/modules
     - "properties", "configuration"
	 - Available only on customer-hosted (NOT Runtime Fabric)
2- Routers
  - Choice : first condition true
  - Scatter/Gather : parallel flows/threads
  - Round Robin : *uses state*, uses branches in a RR fashion
  - First Successful: useful for failover

3- Dataweave
   - Several target formats (output application/json)
   - Use functions (also from library)

4- Error Handling
	- Global/Flow/Processor(Try Scope) 
	- On Error Propagate/Continue - they impact how the flow goes
	- Try Scope for TX Demarcation + Propagate/Continue = TX Management : Propagate-Rollback; Continue- (Partial)Commit; No Error and the scope complete: Commit
	- Protect a Scatter/Gather: Use a Try with Continue, TX?
	
We use the 1-2-3-4 ingredients to create "patterns" for use cases.

Example of Integration Pattern (see Integration Pattern site)
- Dead Letter Channel: Connector (JMS), Router (Choice)/Validator/Error Handling, Dataweave (Transform/Variable)
- Enrichment: Connector (HTTP/Request) Target Variable, Dataweave to perform the enrichment, S/G to do "parallel" enrichment+flatten #[payload..payload]
	
Module 4 - Processing Models
- Synchronous (Request Q/Reply Q - VM Pulish Consume)/Asynchronous A.k.A "Fire&Forget" (Async, VM/JMS Queues Publish)
- Non Blocking/Reactive (Proactor Pattern) + BackPressure
	- Mule: CPU-Lite ca. 10 ms (2*cores) tot. 8 threads
	- Mule: CPU-Intensive up to 1 sec
	- Mule: Blocking I/O several seconds, blocked 80% of thread time, max(2, cores + ((mem - 245760) / 5120))
	- Grizzly: HTTPListener (listening for incoming conn to trigger flows) pool shared
	- Grizzly: HTTPRequest (wait for response to come back) dedicated poll f.e. Request Connector
Based on #cores (mainly) and mem (for blocking i/o).
From 4.3 instead of having 1 executor pool f.e. group, just 1 called "UBER" with max(2, cores + ((mem - 245760) / 5120))
- Streaming (supported in the most important eventsource/connectors e.g. File) (based on filestore / memorystore to buffer)
- (Near-)RealTime vs Batch
- Iterative (scan a collection keeping the order or not, sequential or parallel): e.g. ForEach vs. Parallel ForEach

- Plain Streaming vs. For Each vs. Batch Job. (look at file 4-1-step2)
	- FileStore-based (Repeatable) Streaming 
	- In-memory (Repeatable) streaming
	- Non-Repeatable Streaming
	- Connectors/Components support Streaming: DB, File, HTTP
	- For Each: sequential processing
	- Throughput: Parallel For Each, Batch Job (possible "cap" due to the pre-load queue)
	- For Each + Try Scope + (VM/JMS) Queue --(ACK: AUTO (default))-- child flow (with VM/JMS Listener) does the "real" processing
	- Dead Letter Queue

Module 5 - "Data" Patterns	
	- Enricher + Target Variable + Using Dataweave
	- CDM: Canonical Data Model o(n**2) vs o(n)
	- "Fail Fast". Validators, Schema Validators (XML, JSON), Checkings Scripts, Choices, HTTP Response Validator

Module 6 - Testing Strategies
	- White Box (unit testing: MUnit) / Black Box (integration testing: SoapUI).
	- Suites - Tests - ( Behaviour (Mock, Set Event(Attribute,Payload,Variable,Errors)), Execution (FlowRef) ,Validation )
	- Mock: Isolate External Deps (1- unavailablity, 2- repeatability)
	- Spy: checking that certain components are called (Verify Call)
	- Assert Equals / Assert Expression (DWL - Assert Library)
	- Unit - Integration - Performance (Stress/Soak(Endurance)). (Sandboxes) Terraform (AWS, GCP, Oracle Cloud, Azure)
	- Performance Metrics (Throughput (messages/min), Avg. Response Time, MAx/min Response Time, #Failures/min)
	
Module 7 - Runtime Configurations / Deployment Models
- CloudHub MH: (CP+RT)
- RunTime Fabric: K8S MH: CP; CustHost: RT ("Fabric" also CustHost)
- Customer-Hosted  MH: CP; CustHost: RT
- Private Cloud Edition CustHost (CP+RT)
- (PCF, Pivotal Cloud Foundry).

General Architecture:
- Anypoint Platform Control Plane
- Runtime Plane

Drivers for identify best model:
(Dom)- (Data Locality Requirement) Restriction about where the data is (GDPR) (application data vs metadata) 
- Network Latency
- High Availability / Elasticity+Scaling / Operation Ease+Zero Downtime / Hor-Ver Scaling
- Experience of the team (w/ Containerization+K8S)

Module 8 - State Preservation (Object Store / VM Queues)
OS, OSv2 (Cloud-based, Rest API). OS Connector (CustHost: it uses "local" impl, CloudHub: it uses OSv2)
- Transient. (don't survive restart; cant be shared)
- Persistent (Cluster(RTF): HazelCast in-memory (at least 1 in the cluster needs to survive) /JDBC, CH: OSv2  )
- File State Preservation (it doesn't work well with CH and RTF)
- External Storage (e.g. S3, FTP/SAN/NAS)
VM Queues: they behave pretty much the same. (CH: Amazon SQS).
- HA Profile for a Cluster inflences queues. Reliable (queues are shared); Performant (queues are not shared across nodes)

Module 9 - Logging and Monitoring
Logging:
- Log Aggregation Architecture (Splunk, Elk) (Install Aggregation Agent locally)
	- In CloudHub 1) Disable Default CH Logging; 2) Use additional appenders
	- Log categories and Log levels (use wisely)
- Auditing the Anypoint Platform (6 years) + Audit Log API
Monitoring:
- Anypoint Monitoring (give access + activate monitoring agent)
	- Runtime Manager Dashboard
	- API Analytics
	- Functional Monitoring
- Alerts (on Application events or on Runtime Manager events) Alert on App CPU/Memory only on CloudHub applications.

Module 10 - DevOps / Automation
- Environments (dev, test, qa, prod) and related properties ${env}. (-M-Denv=prod) or (Properties Tab in CloudHub)
- Maven Automation (compile test package install deploy)
- CI/CD (Hooking git branches to Jenkins triggers)
- CD (auto deploy to CH/Anypoint Platform)
	- anypoint-cli script
	- REST APIs (Postman playbook) + client id/client secret (environment level, access manager)
	- Maven plugin (pom.xml)

Module 11 - Transaction Management vs. Compensation
ACID(Atomic, Consistent, Isolated, Durable)
- Local Transactions        : 1 data source involved 
- Global Transactions (XA)  : > 1 data source involved. DB, JMS, VM queues, (!!!NOT Object Store!!!)
	- several RMs (Resource Managers (in the XA driver)) + 1 TM (Transaction Manager = Bitronix)
- Compensation (Saga Pattern: Orchestration (simplest for many steps, Single Point of Failure), Choreography (Event based, Resilient, queue based, Complex) )
- Eventual Consistency

- Transaction Demarcation (with Scope: Try block; Flow level, the Event Source starts a transaction)
	- ALWAYS_BEGIN; JOIN_IF_POSSIBLE
- JMS (can support XA or can manage ACK).
	- AUTO, MANUAL, IMMEDIATE, (DUPS_OK)
	- Ack; NoAck: Recover Session
		- Redelivery Policy (limit the attempts, setup a redelivery delay), MULE:REDELIVERY_EXAHUSTED  -> DLQ

Module 12 - Reliability Pattern

- Good TX Mgmt
- Until Successful
- Validation
- Reconnection Strategy (@ component & @ connector configuration level) - Standard (#retries+frequency)
- Using staging VM/JMS queues (ingestion stage (flow concurrency maxConcurrency=1 to avoid contention) -> processing stage -> dispatcher stage)

------------

Module 13 - High Availability

Module 14 - Performance Optimizations

Module 15 - Application Security 

Module 16 - Infrastructure/Network Security

10.0.0.1/24 = 2**8 = 256
8 x 8 x 8 x 8

22 - 1024
23 - 512
24 - 256
25 - 128
26 - 64
27 - 32


100 applications
you want to cluster x4 each one of those

Total: 4 x 100 = 400 workers
50% bump up: + 200 for zero downtime additional space

Total 600 workers ===> CIDR SIZE: 22


